<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="First Last" />


<title>Untitled</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-1.1/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-1.1/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs && document.readyState && document.readyState === "complete") {
   window.setTimeout(function() {
      hljs.initHighlighting();
   }, 0);
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Hi-C</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/jdblischak/workflowr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Untitled</h1>
<h4 class="author"><em>First Last</em></h4>
<h4 class="date"><em>YYYY-MM-DD</em></h4>

</div>


<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
<!-- Update knitr chunk options -->
<!-- Insert the date the file was last updated -->
<p><strong>Last updated:</strong> 2017-10-30</p>
<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
<p><strong>Code version:</strong> 907bbb5</p>
<!-- Add your analysis here -->
<pre class="r"><code>#This file will examine first the inflation of p-values from the QQ plot at the end of linear_modeling.Rmd, and then the asymmetry seen in the volcano plots from linear modeling.

#First, grab the qqplotting function I utilize from linear_modeling.Rmd:
newqqplot=function(pvals, quant, title){  
  len = length(pvals)
  res=qqplot(-log10((1:len)/(1+len)),pvals,plot.it=F)
  plot(res$x,res$y, main=title, xlab=&quot;Theoretical&quot;, ylab=&quot;Actual&quot;, col=ifelse(res$y&gt;as.numeric(quantile(res$y, quant[1])), ifelse(res$y&gt;as.numeric(quantile(res$y, quant[2])), &quot;red&quot;, &quot;blue&quot;), &quot;black&quot;))
  abline(0, 1)
}

#Load in necessary packages.
library(limma)</code></pre>
<pre><code>Warning: package &#39;limma&#39; was built under R version 3.4.1</code></pre>
<pre class="r"><code>library(plyr)
library(tidyr)
library(data.table)
library(reshape2)</code></pre>
<pre><code>
Attaching package: &#39;reshape2&#39;</code></pre>
<pre><code>The following objects are masked from &#39;package:data.table&#39;:

    dcast, melt</code></pre>
<pre><code>The following object is masked from &#39;package:tidyr&#39;:

    smiths</code></pre>
<pre class="r"><code>library(ggplot2)
library(plotly)</code></pre>
<pre><code>
Attaching package: &#39;plotly&#39;</code></pre>
<pre><code>The following object is masked from &#39;package:ggplot2&#39;:

    last_plot</code></pre>
<pre><code>The following objects are masked from &#39;package:plyr&#39;:

    arrange, mutate, rename, summarise</code></pre>
<pre><code>The following object is masked from &#39;package:stats&#39;:

    filter</code></pre>
<pre><code>The following object is masked from &#39;package:graphics&#39;:

    layout</code></pre>
<pre class="r"><code>library(dplyr)</code></pre>
<pre><code>Warning: package &#39;dplyr&#39; was built under R version 3.4.1</code></pre>
<pre><code>
Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>The following objects are masked from &#39;package:data.table&#39;:

    between, first, last</code></pre>
<pre><code>The following objects are masked from &#39;package:plyr&#39;:

    arrange, count, desc, failwith, id, mutate, rename, summarise,
    summarize</code></pre>
<pre><code>The following objects are masked from &#39;package:stats&#39;:

    filter, lag</code></pre>
<pre><code>The following objects are masked from &#39;package:base&#39;:

    intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>library(Hmisc)</code></pre>
<pre><code>Loading required package: lattice</code></pre>
<pre><code>Loading required package: survival</code></pre>
<pre><code>Loading required package: Formula</code></pre>
<pre><code>
Attaching package: &#39;Hmisc&#39;</code></pre>
<pre><code>The following objects are masked from &#39;package:dplyr&#39;:

    combine, src, summarize</code></pre>
<pre><code>The following object is masked from &#39;package:plotly&#39;:

    subplot</code></pre>
<pre><code>The following objects are masked from &#39;package:plyr&#39;:

    is.discrete, summarize</code></pre>
<pre><code>The following objects are masked from &#39;package:base&#39;:

    format.pval, round.POSIXt, trunc.POSIXt, units</code></pre>
<pre class="r"><code>library(gplots)</code></pre>
<pre><code>
Attaching package: &#39;gplots&#39;</code></pre>
<pre><code>The following object is masked from &#39;package:stats&#39;:

    lowess</code></pre>
<pre class="r"><code>library(stringr)
library(heatmaply)</code></pre>
<pre><code>Loading required package: viridis</code></pre>
<pre><code>Loading required package: viridisLite</code></pre>
<pre><code>
---------------------
Welcome to heatmaply version 0.10.1
Type ?heatmaply for the main documentation.
The github page is: https://github.com/talgalili/heatmaply/

Suggestions and bug-reports can be submitted at: https://github.com/talgalili/heatmaply/issues
Or contact: &lt;tal.galili@gmail.com&gt;

    To suppress this message use:  suppressPackageStartupMessages(library(heatmaply))
---------------------</code></pre>
<pre class="r"><code>library(RColorBrewer)
library(edgeR)
library(tidyverse)</code></pre>
<pre><code>Loading tidyverse: tibble
Loading tidyverse: readr
Loading tidyverse: purrr</code></pre>
<pre><code>Conflicts with tidy packages ----------------------------------------------</code></pre>
<pre><code>arrange():   dplyr, plotly, plyr
between():   dplyr, data.table
combine():   dplyr, Hmisc
compact():   purrr, plyr
count():     dplyr, plyr
failwith():  dplyr, plyr
filter():    dplyr, plotly, stats
first():     dplyr, data.table
id():        dplyr, plyr
lag():       dplyr, stats
last():      dplyr, data.table
mutate():    dplyr, plotly, plyr
rename():    dplyr, plotly, plyr
src():       dplyr, Hmisc
summarise(): dplyr, plotly, plyr
summarize(): dplyr, Hmisc, plyr
transpose(): purrr, data.table</code></pre>
<pre class="r"><code>library(compiler)
library(bedr)</code></pre>
<pre><code>

######################
#### bedr v1.0.3 ####
######################

checking binary availability...
  * Checking path for bedtools... FAIL
  * Checking path for bedops... FAIL
  * Checking path for tabix... FAIL
tests and examples will be skipped on R CMD check if binaries are missing</code></pre>
<pre class="r"><code>enableJIT(3)</code></pre>
<pre><code>[1] 3</code></pre>
<pre class="r"><code>#Now, as always, read in data files modified by initial_QC.Rmd and linear_modeling.Rmd
full.data &lt;- fread(&quot;~/Desktop/Hi-C/full.data.10.Oct17&quot;, header = TRUE, data.table=FALSE, stringsAsFactors = FALSE)</code></pre>
<pre><code>
Read 0.0% of 3151443 rows
Read 1.9% of 3151443 rows
Read 3.8% of 3151443 rows
Read 5.7% of 3151443 rows
Read 7.6% of 3151443 rows
Read 9.5% of 3151443 rows
Read 11.4% of 3151443 rows
Read 13.3% of 3151443 rows
Read 15.2% of 3151443 rows
Read 17.1% of 3151443 rows
Read 19.4% of 3151443 rows
Read 21.3% of 3151443 rows
Read 23.5% of 3151443 rows
Read 25.7% of 3151443 rows
Read 27.9% of 3151443 rows
Read 30.1% of 3151443 rows
Read 32.4% of 3151443 rows
Read 34.6% of 3151443 rows
Read 36.8% of 3151443 rows
Read 39.0% of 3151443 rows
Read 41.3% of 3151443 rows
Read 43.2% of 3151443 rows
Read 45.1% of 3151443 rows
Read 47.0% of 3151443 rows
Read 48.9% of 3151443 rows
Read 50.8% of 3151443 rows
Read 53.0% of 3151443 rows
Read 55.2% of 3151443 rows
Read 57.4% of 3151443 rows
Read 59.7% of 3151443 rows
Read 61.9% of 3151443 rows
Read 63.8% of 3151443 rows
Read 65.7% of 3151443 rows
Read 67.9% of 3151443 rows
Read 69.8% of 3151443 rows
Read 71.7% of 3151443 rows
Read 72.7% of 3151443 rows
Read 74.9% of 3151443 rows
Read 76.8% of 3151443 rows
Read 78.7% of 3151443 rows
Read 80.6% of 3151443 rows
Read 82.5% of 3151443 rows
Read 84.4% of 3151443 rows
Read 86.3% of 3151443 rows
Read 88.2% of 3151443 rows
Read 90.1% of 3151443 rows
Read 92.0% of 3151443 rows
Read 93.9% of 3151443 rows
Read 95.8% of 3151443 rows
Read 97.7% of 3151443 rows
Read 99.6% of 3151443 rows
Read 3151443 rows and 328 (of 328) columns from 5.053 GB file in 00:01:22</code></pre>
<pre class="r"><code>data.4 &lt;- fread(&quot;~/Desktop/Hi-C/data.4.10.Oct17&quot;, header=TRUE, data.table=FALSE, stringsAsFactors = FALSE)</code></pre>
<pre><code>
Read 17.1% of 292670 rows
Read 37.6% of 292670 rows
Read 58.1% of 292670 rows
Read 78.6% of 292670 rows
Read 99.1% of 292670 rows
Read 292670 rows and 328 (of 328) columns from 0.605 GB file in 00:00:07</code></pre>
<pre class="r"><code>#This is the QQ plot for species from the linear model for Hi-C values from linear_modeling.Rmd. We can see a significant inflation of p-values here rising above the expected normal distribution alarmingly quickly:
newqqplot(-log10(data.4$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Species P-vals, Data | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#In order to check that this extreme inflation of p values is not merely a technical artifact, here I try shuffling the species labels and running the linear model again. I would hope to see a more normal QQplot and this would perhaps suggest this the inflation seen is due to true biological effects, rather than technical factors. The fake designs just have some species swapped; the first two fake designs are balanced across sex and batch, and the second two are balanced with respect to batch (equal numbers of humans and chimps in both), but any sex-species interaction would be confounded with batch (since all members of a species in one batch are the same sex). Note that this ultimately shouldn&#39;t matter since I&#39;m just for checking QQ normality here, especially since I&#39;ll start with the full model but then also remove batch and sex as covariates and re-check the QQ plot, to rule out overfitting.
fake.meta1 &lt;- data.frame(&quot;SP&quot;=c(&quot;H&quot;, &quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;C&quot;, &quot;H&quot;), &quot;SX&quot;=c(&quot;F&quot;, &quot;M&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;), &quot;Batch&quot;=c(1, 1, 1, 1, 2, 2, 2, 2))
fake.meta2 &lt;- data.frame(&quot;SP&quot;=c(&quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;H&quot;, &quot;H&quot;, &quot;C&quot;), &quot;SX&quot;=c(&quot;F&quot;, &quot;M&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;), &quot;Batch&quot;=c(1, 1, 1, 1, 2, 2, 2, 2))
fake.meta3 &lt;- data.frame(&quot;SP&quot;=c(&quot;H&quot;, &quot;C&quot;, &quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;H&quot;), &quot;SX&quot;=c(&quot;F&quot;, &quot;M&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;), &quot;Batch&quot;=c(1, 1, 1, 1, 2, 2, 2, 2))
fake.meta4 &lt;- data.frame(&quot;SP&quot;=c(&quot;C&quot;, &quot;H&quot;, &quot;H&quot;, &quot;C&quot;, &quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;H&quot;), &quot;SX&quot;=c(&quot;F&quot;, &quot;M&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;), &quot;Batch&quot;=c(1, 1, 1, 1, 2, 2, 2, 2))

#First, test out the fake metadataframess utilizing the linear model with all covariates included--species, sex, and batch.
lmFit(data.4[,304:311], model.matrix(~1+fake.meta1$SP+fake.meta1$SX+fake.meta1$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake1
lmFit(data.4[,304:311], model.matrix(~1+fake.meta2$SP+fake.meta2$SX+fake.meta2$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake2
lmFit(data.4[,304:311], model.matrix(~1+fake.meta3$SP+fake.meta3$SX+fake.meta3$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake3</code></pre>
<pre><code>Coefficients not estimable: fake.meta3$SXM </code></pre>
<pre><code>Warning: Partial NA coefficients for 292670 probe(s)</code></pre>
<pre><code>Warning in ebayes(fit = fit, proportion = proportion, stdev.coef.lim =
stdev.coef.lim, : Estimation of var.prior failed - set to default value</code></pre>
<pre class="r"><code>lmFit(data.4[,304:311], model.matrix(~1+fake.meta4$SP+fake.meta4$SX+fake.meta4$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake4

newqqplot(-log10(fake1$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design 1 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake2$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design 2 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-3.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake3$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design 3 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-4.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake4$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design 4 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-5.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#While these QQ plots are nice in that they no longer show inflation of p-values quickly, many of them show slight deflation. Here I try doing the same thing again but without sex and then without batch, and then without both, as covariates--to account for the possibility that inclusion of these covariates in the model is overfitting:
lmFit(data.4[,304:311], model.matrix(~1+fake.meta1$SP+fake.meta1$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake1
lmFit(data.4[,304:311], model.matrix(~1+fake.meta2$SP+fake.meta2$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake2
lmFit(data.4[,304:311], model.matrix(~1+fake.meta3$SP+fake.meta3$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake3
lmFit(data.4[,304:311], model.matrix(~1+fake.meta4$SP+fake.meta4$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake4
newqqplot(-log10(fake1$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no SX, 1 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-6.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake2$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no SX, 2 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-7.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake3$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no SX, 3 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-8.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake4$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no SX, 4 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-9.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>lmFit(data.4[,304:311], model.matrix(~1+fake.meta1$SP+fake.meta1$SX)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake1
lmFit(data.4[,304:311], model.matrix(~1+fake.meta2$SP+fake.meta2$SX)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake2
lmFit(data.4[,304:311], model.matrix(~1+fake.meta3$SP+fake.meta3$SX)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake3</code></pre>
<pre><code>Coefficients not estimable: fake.meta3$SXM </code></pre>
<pre><code>Warning: Partial NA coefficients for 292670 probe(s)

Warning: Estimation of var.prior failed - set to default value</code></pre>
<pre class="r"><code>lmFit(data.4[,304:311], model.matrix(~1+fake.meta4$SP+fake.meta4$SX)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake4
newqqplot(-log10(fake1$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no BTC, 1 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-10.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake2$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no BTC, 2 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-11.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake3$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no BTC, 3 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-12.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake4$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no BTC, 4 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-13.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>lmFit(data.4[,304:311], model.matrix(~1+fake.meta1$SP)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake1
lmFit(data.4[,304:311], model.matrix(~1+fake.meta2$SP)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake2
lmFit(data.4[,304:311], model.matrix(~1+fake.meta3$SP)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake3
lmFit(data.4[,304:311], model.matrix(~1+fake.meta4$SP)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake4
newqqplot(-log10(fake1$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design SP only, 1 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-14.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake2$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design SP only, 2 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-15.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake3$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design SP only, 3 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-16.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake4$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design SP only, 4 | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-17.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#These are slightly better, but many still show some small degree of deflation. In an attempt to ID the problem, I now add several other metrics measuring differences in bin sizes and pair distances between humans and chimps, to help identify differences that may be primarily driven by mapping of orthology or different genome builds rather than true biology. I will then subset the QQ plots to particular classes of these hits and see if any pattern emerges. This utilizes the normal set of p-values from the original design conditioned upon discovery in 4 individuals. To do this, I first have to pull out the mean start and end positions of bins for each of the species from the data:
H1startCmean &lt;- rowMeans(data.4[,c(&#39;Hstart1-C&#39;, &#39;Hstart1-D&#39;, &#39;Hstart1-G&#39;, &#39;Hstart1-H&#39;)], na.rm=TRUE)
H1endCmean &lt;- rowMeans(data.4[,c(&#39;Hend1-C&#39;, &#39;Hend1-D&#39;, &#39;Hend1-G&#39;, &#39;Hend1-H&#39;)], na.rm=TRUE)
H2startCmean &lt;- rowMeans(data.4[,c(&#39;Hstart2-C&#39;, &#39;Hstart2-D&#39;, &#39;Hstart2-G&#39;, &#39;Hstart2-H&#39;)], na.rm=TRUE)
H2endCmean &lt;- rowMeans(data.4[,c(&#39;Hend2-C&#39;, &#39;Hend2-D&#39;, &#39;Hend2-G&#39;, &#39;Hend2-H&#39;)], na.rm=TRUE)

C1startHmean &lt;- rowMeans(data.4[,c(&#39;Cstart1-A&#39;, &#39;Cstart1-B&#39;, &#39;Cstart1-E&#39;, &#39;Cstart1-F&#39;)], na.rm=TRUE) #this is identical and easier.
C1endHmean &lt;- rowMeans(data.4[,c(&#39;Cend1-A&#39;, &#39;Cend1-B&#39;, &#39;Cend1-E&#39;, &#39;Cend1-F&#39;)], na.rm=TRUE)
C2startHmean &lt;- rowMeans(data.4[,c(&#39;Cstart2-A&#39;, &#39;Cstart2-B&#39;, &#39;Cstart2-E&#39;, &#39;Cstart2-F&#39;)], na.rm=TRUE)
C2endHmean &lt;- rowMeans(data.4[,c(&#39;Cend2-A&#39;, &#39;Cend2-B&#39;, &#39;Cend2-E&#39;, &#39;Cend2-F&#39;)], na.rm=TRUE)
  
#Now, I use these data to add columns to the data frame for the sizes of bins and distance between bins. Note that I am only really looking at differences in the size of the &quot;orthologous&quot; bins called through liftover, as compared to their original size (10kb). Bin size differences in the values at the start of each individual&#39;s portion of the data frame for coordinates matching that species are merely due to size differences in reciprocal best hits liftover. The true size of bins within their own species is always 10kb. So here bin sizes being appended to the data frame are for lifted-over bins. I do the distance differences based on the HC-pair values (H1/H2 and C1/C2) that have been rounded to the nearest 10kb from the original values given by homer; since this should be balanced across species it shouldn&#39;t matter much. Worst case it would make the estimate off by 20kb, maximum.
H1sizeC &lt;- H1endCmean-H1startCmean
H2sizeC &lt;- H2endCmean-H2startCmean
data.4$H1diff &lt;- abs(10000-H1sizeC)
data.4$H2diff &lt;- abs(10000-H2sizeC)
C1sizeH &lt;- C1endHmean-C1startHmean
C2sizeH &lt;- C2endHmean-C2startHmean
data.4$C1diff &lt;- abs(10000-C1sizeH)
data.4$C2diff &lt;- abs(10000-C2sizeH)
data.4$Hdist &lt;- abs(as.numeric(sub(&quot;.*-&quot;, &quot;&quot;, data.4$H2))-as.numeric(sub(&quot;.*-&quot;, &quot;&quot;, data.4$H1)))
data.4$Cdist &lt;- abs(as.numeric(sub(&quot;.*-&quot;, &quot;&quot;, data.4$C2))-as.numeric(sub(&quot;.*-&quot;, &quot;&quot;, data.4$C1)))
data.4$dist_diff &lt;- abs(data.4$Hdist-data.4$Cdist)

#Now I look at the distributions of some of these metrics to inform me about how best to bin the data for filtering and further QC checking.
quantile(data.4$H1diff, na.rm=TRUE)</code></pre>
<pre><code>         0%         25%         50%         75%        100% 
   0.000000    8.666667   21.000000   52.500000 1104.000000 </code></pre>
<pre class="r"><code>quantile(data.4$H2diff, na.rm=TRUE)</code></pre>
<pre><code>    0%    25%    50%    75%   100% 
   0.0    8.5   21.0   52.0 1098.5 </code></pre>
<pre class="r"><code>quantile(data.4$C1diff, na.rm=TRUE)</code></pre>
<pre><code>         0%         25%         50%         75%        100% 
   0.000000    8.666667   21.000000   52.000000 1097.000000 </code></pre>
<pre class="r"><code>quantile(data.4$C2diff, na.rm=TRUE)</code></pre>
<pre><code>        0%        25%        50%        75%       100% 
   0.00000    8.50000   20.66667   51.33333 1099.00000 </code></pre>
<pre class="r"><code>quantile(data.4$dist_diff, na.rm=TRUE)</code></pre>
<pre><code>      0%      25%      50%      75%     100% 
       0        0        0    10000 77730000 </code></pre>
<pre class="r"><code>#From this I can see that the majority of bin size differences are relatively small (&lt;25 bp), and the majority of hits do not have a difference in distance between the mates in a pair across the species (all the way up to 50th percentile the distance difference is still 0). Now I&#39;ll take a look at some QQ plots filtering along these values to get an idea of if any of these technical orthology-calling artifacts are driving the inflation we see.
newqqplot(-log10(filter(data.4, H1diff&lt;21&amp;H2diff&lt;21&amp;C1diff&lt;21&amp;C2diff&lt;21)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Bin Size Changes &lt; 21 bp | 4&quot;) #We can see that the QQplot looks a bit better if we only utilize hits where the bin size difference is less than the 50% percentile of their distribution.</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-18.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(data.4, H1diff&gt;=21&amp;H2diff&gt;=21&amp;C1diff&gt;=21&amp;C2diff&gt;=21)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Bin Size Changes &gt;= 21bp | 4&quot;) #This doesn&#39;t look much different--what about the case where there are large differences in the size?</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-19.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(data.4, H1diff&gt;=100|H2diff&gt;=100|C1diff&gt;=100|C2diff&gt;=100)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Bin Size Changes &gt;= 100 bp | 4&quot;) #It&#39;s hard to know what to make of this since here I am just allowing for any bin to have a size change greater than 100 bp. It looks fairly similar to the QQplot of the full data.</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-20.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(data.4, H1diff&gt;=500|H2diff&gt;=500|C1diff&gt;=500|C2diff&gt;=500)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Bin Size Changes &gt;= 500 bp | 4&quot;) #It&#39;s hard to know what to make of this since here I am just allowing for any bin to have a size change greater than 500 bp.</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-21.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(data.4, H1diff&gt;=1000|H2diff&gt;=1000|C1diff&gt;=1000|C2diff&gt;=1000)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Bin Size Changes &gt;= 100 bp | 4&quot;) #It&#39;s hard to know what to make of this since here I am just allowing for any bin to have a size change greater than 1kb.</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-22.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#It may be hard to say anything super definitive about the bin size changes from these plots, but the fact that they all still show inflation, and I don&#39;t see any stark difference between bin size changes exceeding 100 bp, suggests to me that bin size is having a minimal effect here. Still, we will include it when looking at filtering criteria below for figuring out what hits might need to be removed still.

newqqplot(-log10(filter(data.4, dist_diff&gt;=100000)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Distance Diff &gt;= 100kb | 4&quot;) #This is good to know--see EXTREMELY strong inflation amongst this class of p-values, perhaps giving another criteria for filtering</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-23.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(data.4, dist_diff&gt;=50000)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Distance Diff &gt;= 50kb | 4&quot;) #This is good to know--see that the inflation is a little weaker if we move towards including more pairs that have smaller distance differences between the species. What about pairs where there is no difference?</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-24.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(data.4, dist_diff==0)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, NO Distance Diff | 4&quot;) #Values are still inflated, but the first solid 50% of the distribution stays along the normal line--this is great!</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-25.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(data.4, dist_diff&lt;=20000)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Distance Diff &lt;=20kb | 4&quot;) #And now we can see the trend in the opposite direction--SLIGHT inflation of the p-values when including more hits that have a larger distance difference.</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-26.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#Based on the quantiles from before, the size differences have relatively little variation in their distribution. Hence I will take them and summarize them as a single value here:
sizediffs &lt;- rowMeans(select(data.4, H1diff, H2diff, C1diff, C2diff), na.rm=TRUE)
quantile(sizediffs, probs=seq(0, 1, 0.2))</code></pre>
<pre><code>        0%        20%        40%        60%        80%       100% 
   0.00000   13.50000   23.33333   42.18750  109.50000 1000.87500 </code></pre>
<pre class="r"><code>#Now what I would like to do is find classes of hits--combinations between size and distance differences--that comprise roughly 10% of the data, or ~30k hits here. I will look at these classes in a 3-dimensional plot that includes size and distance differences as two of the axes, and the FDR from linear modeling on the 3rd. What I am in search of are classes of hits that show inflated FDR.
plot3d &lt;- data.frame(bin_min=pmin(data.4$H1diff, data.4$H2diff, data.4$C1diff, data.4$C2diff, na.rm=TRUE), bin_max=pmax(data.4$H1diff, data.4$H2diff, data.4$C1diff, data.4$C2diff, na.rm=TRUE), bin_mean=sizediffs, dist_diff=data.4$dist_diff, FDR=data.4$sp_BH_pval)

#Of course, I already inherently know I will have a difficult time finding sets large enough with the bigger differences in distance, as only 10k or so of the hits even have a distance difference greater than 50kb. About half the hits have no distance difference, and of the remaining half, about half have size differences of 1-2 bins (10-20 kb), and half have greater size differences.

#First, I go in search of sets that will be large enough.
nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&lt;10000)) #30k, a class of minimal changes--no distance difference, and minimal size difference.</code></pre>
<pre><code>[1] 30420</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&lt;10000)) #30k, still minimal changes</code></pre>
<pre><code>[1] 30271</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&lt;10000)) #30k, minimal changes still, bin size getting up there</code></pre>
<pre><code>[1] 30916</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&lt;10000)) #30k, minimal changes still, bin size even higher though</code></pre>
<pre><code>[1] 30250</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&lt;10000)) #And there&#39;s another 30k! With big bin size changes.</code></pre>
<pre><code>[1] 30641</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)) #19k, a class of minimal changes--no size difference, and minimal distance difference (1-2 bins off).</code></pre>
<pre><code>[1] 19801</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)) #19k, small size difference, and minimal distance difference (1-2 bins off, 10-20 kb).</code></pre>
<pre><code>[1] 19419</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)) #19k, minimal changes still, bin size getting up there, and minimal distance difference (1-2 bins off, 10-20 kb).</code></pre>
<pre><code>[1] 19575</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)) #19k, minimal changes still, bin size even higher though, and minimal distance difference (1-2 bins off, 10-20 kb).</code></pre>
<pre><code>[1] 19897</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)) #And there&#39;s another 19k! With big bin size changes, and minimal distance difference (1-2 bins off, 10-20 kb).</code></pre>
<pre><code>[1] 19920</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&gt;20000)) #8k, a class of large changes--big distance difference, and minimal size difference.</code></pre>
<pre><code>[1] 8674</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&gt;20000)) #8k, a class of large changes--big distance difference, and relatively small size difference.</code></pre>
<pre><code>[1] 8382</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&gt;20000)) #8k, a class of large changes--big distance difference, and median size difference.</code></pre>
<pre><code>[1] 8157</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&gt;20000)) #8k, a class of large changes--big distance difference, and fairly large size difference.</code></pre>
<pre><code>[1] 8395</code></pre>
<pre class="r"><code>nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&gt;20000)) #8k, a class of the largest changes--big distance difference, and big size difference.</code></pre>
<pre><code>[1] 7952</code></pre>
<pre class="r"><code>#Now, create a data frame with these classes, their sizes, and the number of hits in each of the classes that is at FDR &lt;= 0.05.
true3d &lt;- data.frame(dist_class=c(rep(&quot;none&quot;, 5), rep(&quot;short&quot;, 5), rep(&quot;long&quot;, 5)), bin_quant=rep(1:5, 3), set_size=c(nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&lt;10000)), nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&lt;10000)), nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&lt;10000)), nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&lt;10000)), nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&lt;10000)), nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)), nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)), nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)), nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)), nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)), nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&gt;20000)), nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&gt;20000)), nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&gt;20000)), nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&gt;20000)), nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&gt;20000))), num_sig=c(nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&lt;10000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&lt;10000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&lt;10000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&lt;10000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&lt;10000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&gt;20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&gt;20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&gt;20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&gt;20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&gt;20000&amp;FDR&lt;=0.05))))
true3d$prop &lt;- true3d$num_sig/true3d$set_size #Get the proportion of these different sets that are significant (at or below 5% FDR)
#I will then take this data frame and export it to plot.ly&#39;s online interface, in order to make a 3D graph that will allow me to visualize FDR significance inflation in any of these sets (and subsequently filter them out).

#Now, I once again show the volcano plot for 4 individuals. Observe the stark asymmetry with a pile-up of hits on the left side as compared to the right.
volcplot.4 &lt;- data.frame(pval=-log10(data.4$sp_pval), beta=data.4$sp_beta, species=data.4$disc_species, chr=data.4$Hchr)
ggplot(data=volcplot.4, aes(x=beta, y=pval)) + geom_point() + xlab(&quot;Log2 Fold Change in Contact Frequency&quot;) + ylab(&quot;-log10 BH-corrected p-values&quot;) + ggtitle(&quot;Contact Frequency Differences | 4 Individuals&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-27.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(data=volcplot.4, aes(x=beta, y=pval, color=species)) + geom_point() + xlab(&quot;Log2 Fold Change in Contact Frequency&quot;) + ylab(&quot;-log10 BH-corrected p-values&quot;) + ggtitle(&quot;Contact Frequency Differences Colored by Species of Discovery | 4&quot;)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-28.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#As expected, we see that hits which produce a strong negative beta in the linear model (suggesting a marked decrease in contact frequency in humans as compared to chimps) are primarily discovered as significant by homer in chimpanzees. The inverse also holds true for human discoveries. This is reassuring, but still, why the asymmetry? Here I break this plot down on a chromosome-by-chromosome basis to see if this is being driven by individual chromosomes ore is an overall issue with the technique or its processing:
#First rearrange chrs to make a prettier plot that has chrs sequential:
levels(volcplot.4$chr)</code></pre>
<pre><code> [1] &quot;chr1&quot;  &quot;chr10&quot; &quot;chr11&quot; &quot;chr12&quot; &quot;chr13&quot; &quot;chr14&quot; &quot;chr15&quot; &quot;chr16&quot;
 [9] &quot;chr17&quot; &quot;chr18&quot; &quot;chr19&quot; &quot;chr2&quot;  &quot;chr20&quot; &quot;chr21&quot; &quot;chr22&quot; &quot;chr3&quot; 
[17] &quot;chr4&quot;  &quot;chr5&quot;  &quot;chr6&quot;  &quot;chr7&quot;  &quot;chr8&quot;  &quot;chr9&quot;  &quot;chrX&quot;  &quot;chrY&quot; </code></pre>
<pre class="r"><code>volcplot.4$chr &lt;- factor(volcplot.4$chr, levels(volcplot.4$chr)[c(1, 12, 16:22, 2:11, 13:15, 23:24)]) #Reorder factor levels!
levels(volcplot.4$chr)</code></pre>
<pre><code> [1] &quot;chr1&quot;  &quot;chr2&quot;  &quot;chr3&quot;  &quot;chr4&quot;  &quot;chr5&quot;  &quot;chr6&quot;  &quot;chr7&quot;  &quot;chr8&quot; 
 [9] &quot;chr9&quot;  &quot;chr10&quot; &quot;chr11&quot; &quot;chr12&quot; &quot;chr13&quot; &quot;chr14&quot; &quot;chr15&quot; &quot;chr16&quot;
[17] &quot;chr17&quot; &quot;chr18&quot; &quot;chr19&quot; &quot;chr20&quot; &quot;chr21&quot; &quot;chr22&quot; &quot;chrX&quot;  &quot;chrY&quot; </code></pre>
<pre class="r"><code>ggplot(volcplot.4, aes(x=beta, y=pval, color=species)) + geom_point(size=0.001) + ggtitle(&quot;Volcano Plots by Chr&quot;) + facet_wrap(~as.factor(chr), nrow=5, ncol=5) + guides(color=FALSE)</code></pre>
<p><img src="figure/linear_modeling_QC.Rmd/unnamed-chunk-1-29.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#This is extremely interesting. It appears that the asymmetry seen is being driven primarily by only some of the chromosomes, and particularly ones where large-scale rearrangements have transpired between humans and chimps (e.g. chrs 2, 16, 17). This will warrant further investigation in another element of the analysis; for now, I am satisfied that the asymmetry is not an issue with the entire dataset but is confined to individual chromosomes. I will need to go quantify some of the orthology calling on these chromosomes later to confirm high quality of the data.

#Write out the modified dfs.</code></pre>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<!-- Insert the session information into the document -->
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.4.0 (2017-04-21)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: OS X El Capitan 10.11.6

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] compiler  stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
 [1] bindrcpp_0.2       bedr_1.0.3         purrr_0.2.2.2     
 [4] readr_1.1.1        tibble_1.3.3       tidyverse_1.1.1   
 [7] edgeR_3.18.1       RColorBrewer_1.1-2 heatmaply_0.10.1  
[10] viridis_0.4.0      viridisLite_0.2.0  stringr_1.2.0     
[13] gplots_3.0.1       Hmisc_4.0-3        Formula_1.2-2     
[16] survival_2.41-3    lattice_0.20-35    dplyr_0.7.2       
[19] plotly_4.7.0       ggplot2_2.2.1      reshape2_1.4.2    
[22] data.table_1.10.4  tidyr_0.6.3        plyr_1.8.4        
[25] limma_3.32.4      

loaded via a namespace (and not attached):
 [1] nlme_3.1-131         bitops_1.0-6         lubridate_1.6.0     
 [4] httr_1.3.1           rprojroot_1.2        prabclus_2.2-6      
 [7] tools_3.4.0          backports_1.1.0      R6_2.2.2            
[10] rpart_4.1-11         KernSmooth_2.23-15   lazyeval_0.2.0      
[13] colorspace_1.3-2     trimcluster_0.1-2    nnet_7.3-12         
[16] gridExtra_2.2.1      mnormt_1.5-5         VennDiagram_1.6.17  
[19] git2r_0.19.0         rvest_0.3.2          htmlTable_1.9       
[22] TSP_1.1-5            xml2_1.1.1           labeling_0.3        
[25] diptest_0.75-7       caTools_1.17.1       scales_0.4.1        
[28] checkmate_1.8.3      DEoptimR_1.0-8       mvtnorm_1.0-6       
[31] psych_1.7.5          robustbase_0.92-7    digest_0.6.12       
[34] foreign_0.8-69       R.utils_2.5.0        rmarkdown_1.6       
[37] base64enc_0.1-3      pkgconfig_2.0.1      htmltools_0.3.6     
[40] readxl_1.0.0         htmlwidgets_0.9      rlang_0.1.1         
[43] rstudioapi_0.7       bindr_0.1            jsonlite_1.5        
[46] mclust_5.3           gtools_3.5.0         R.oo_1.21.0         
[49] acepack_1.4.1        dendextend_1.5.2     magrittr_1.5        
[52] modeltools_0.2-21    futile.logger_1.4.3  Matrix_1.2-10       
[55] Rcpp_0.12.12         munsell_0.4.3        R.methodsS3_1.7.1   
[58] stringi_1.1.5        whisker_0.3-2        yaml_2.1.14         
[61] MASS_7.3-47          flexmix_2.3-14       grid_3.4.0          
[64] parallel_3.4.0       gdata_2.18.0         crayon_1.3.4        
[67] forcats_0.2.0        haven_1.1.0          splines_3.4.0       
[70] hms_0.3              locfit_1.5-9.1       knitr_1.17          
[73] fpc_2.1-10           codetools_0.2-15     stats4_3.4.0        
[76] futile.options_1.0.0 glue_1.1.1           gclus_1.3.1         
[79] evaluate_0.10.1      latticeExtra_0.6-28  lambda.r_1.2        
[82] modelr_0.1.1         foreach_1.4.3        testthat_1.0.2      
[85] cellranger_1.1.0     gtable_0.2.0         kernlab_0.9-25      
[88] assertthat_0.2.0     broom_0.4.2          class_7.3-14        
[91] seriation_1.2-2      iterators_1.0.8      registry_0.3        
[94] cluster_2.0.6       </code></pre>
</div>

<hr>
<p>
    This <a href="http://rmarkdown.rstudio.com">R Markdown</a> site was created with <a href="https://github.com/jdblischak/workflowr">workflowr</a>
</p>
<hr>

<!-- To enable disqus, uncomment the section below and provide your disqus_shortname -->

<!-- disqus
  <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'rmarkdown'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Ittai Eres" />

<meta name="date" content="2018-01-23" />

<title>Juicer Linear Modeling QC</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-4.5.0/css/font-awesome.min.css" rel="stylesheet" />

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}

.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
  padding-left: 25px;
  text-indent: 0;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Hi-C</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="about.html">About</a>
</li>
<li>
  <a href="license.html">License</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/jdblischak/workflowr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Juicer Linear Modeling QC</h1>
<h4 class="author"><em>Ittai Eres</em></h4>
<h4 class="date"><em>2018-01-23</em></h4>

</div>


<!-- The file analysis/chunks.R contains chunks that define default settings
shared across the workflowr files. -->
<!-- Update knitr chunk options -->
<!-- Insert the date the file was last updated -->
<p><strong>Last updated:</strong> 2018-01-23</p>
<!-- Insert the code version (Git commit SHA1) if Git repository exists and R
 package git2r is installed -->
<p><strong>Code version:</strong> c2172a7</p>
<!-- Add your analysis here -->
<div id="qc-on-qq-plots" class="section level3">
<h3>QC on QQ Plots</h3>
<p>Having observed inflated p-values in QQ plots from doing linear modeling, as well as a stark asymmetry in the distribution of betas for the species term in the volcano plot, here I move to examine both issues. The QQ plot issue is not truly concerning, as we were not necessarily expecting normality in this set of hits enriched for significant Hi-C contacts. It seems likely that any set of significant Hi-C hits called independently in each species will have some inflation in the significance of a species term for linearly modeling the interaction frequencies. That the QQ plot does not look like a GWAS QQ plot is not truly concerning, however, just to be sure, first I will run a series of QQ plots once again after shuffling some of the metadata labels. This simply ensures the inflation seen is not an artifact of processing. I tackle the volcano plot asymmetry after alleviating QQ plot concerns and doing some further genomic filtering explained below.</p>
<pre class="r"><code>#This file will examine first the inflation of p-values from the QQ plot at the end of linear_modeling.Rmd, and then the asymmetry seen in the volcano plots from linear modeling.

#First, grab the qqplotting function I utilize from linear_modeling.Rmd:
newqqplot=function(pvals, quant, title){  
  len = length(pvals)
  res=qqplot(-log10((1:len)/(1+len)),pvals,plot.it=F)
  plot(res$x,res$y, main=title, xlab=&quot;Theoretical&quot;, ylab=&quot;Actual&quot;, col=ifelse(res$y&gt;as.numeric(quantile(res$y, quant[1])), ifelse(res$y&gt;as.numeric(quantile(res$y, quant[2])), &quot;red&quot;, &quot;blue&quot;), &quot;black&quot;))
  abline(0, 1)
}

#Now, as always, read in data files modified by initial_QC.Rmd and linear_modeling.Rmd
full.data &lt;- fread(&quot;~/Desktop/Hi-C/juicer.full.data.10.2018&quot;, header = TRUE, data.table=FALSE, stringsAsFactors = FALSE, showProgress = FALSE)

#This is the QQ plot for species from the linear model for Hi-C values from linear_modeling.Rmd. We can see a significant inflation of p-values here rising above the expected normal distribution alarmingly quickly:
newqqplot(-log10(full.data$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Species P-vals, Data | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#In order to check that this extreme inflation of p values is not merely a technical artifact, here I try shuffling the species labels and running the linear model again. I would hope to see a more normal QQplot and this would perhaps suggest this the inflation seen is due to true biological effects, rather than technical factors. The fake designs just have some species swapped; the first two fake designs are balanced across sex and batch, and the second two are balanced with respect to batch (equal numbers of humans and chimps in both), but any sex-species interaction would be confounded with batch (since all members of a species in one batch are the same sex). Note that this ultimately shouldn&#39;t matter since I&#39;m just for checking QQ normality here, especially since I&#39;ll start with the full model but then also remove batch and sex as covariates and re-check the QQ plot, to rule out overfitting.
fake.meta1 &lt;- data.frame(&quot;SP&quot;=c(&quot;H&quot;, &quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;C&quot;, &quot;H&quot;), &quot;SX&quot;=c(&quot;F&quot;, &quot;M&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;), &quot;Batch&quot;=c(1, 1, 1, 1, 2, 2, 2, 2))
fake.meta2 &lt;- data.frame(&quot;SP&quot;=c(&quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;H&quot;, &quot;H&quot;, &quot;C&quot;), &quot;SX&quot;=c(&quot;F&quot;, &quot;M&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;), &quot;Batch&quot;=c(1, 1, 1, 1, 2, 2, 2, 2))
fake.meta3 &lt;- data.frame(&quot;SP&quot;=c(&quot;H&quot;, &quot;C&quot;, &quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;H&quot;), &quot;SX&quot;=c(&quot;F&quot;, &quot;M&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;), &quot;Batch&quot;=c(1, 1, 1, 1, 2, 2, 2, 2))
fake.meta4 &lt;- data.frame(&quot;SP&quot;=c(&quot;C&quot;, &quot;H&quot;, &quot;H&quot;, &quot;C&quot;, &quot;C&quot;, &quot;H&quot;, &quot;C&quot;, &quot;H&quot;), &quot;SX&quot;=c(&quot;F&quot;, &quot;M&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;F&quot;), &quot;Batch&quot;=c(1, 1, 1, 1, 2, 2, 2, 2))

#First, test out the fake metadataframess utilizing the linear model with all covariates included--species, sex, and batch.
lmFit(full.data[,112:119], model.matrix(~1+fake.meta1$SP+fake.meta1$SX+fake.meta1$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake1
lmFit(full.data[,112:119], model.matrix(~1+fake.meta2$SP+fake.meta2$SX+fake.meta2$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake2
lmFit(full.data[,112:119], model.matrix(~1+fake.meta3$SP+fake.meta3$SX+fake.meta3$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake3</code></pre>
<pre><code>Coefficients not estimable: fake.meta3$SXM </code></pre>
<pre><code>Warning: Partial NA coefficients for 12876 probe(s)</code></pre>
<pre><code>Warning in ebayes(fit = fit, proportion = proportion, stdev.coef.lim =
stdev.coef.lim, : Estimation of var.prior failed - set to default value</code></pre>
<pre class="r"><code>lmFit(full.data[,112:119], model.matrix(~1+fake.meta4$SP+fake.meta4$SX+fake.meta4$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake4

newqqplot(-log10(fake1$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design 1 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake2$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design 2 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-3.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake3$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design 3 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-4.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake4$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design 4 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-5.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#While these QQ plots are nice in that they no longer show inflation of p-values quickly, many of them show slight deflation. Here I try doing the same thing again but without sex and then without batch, and then without both, as covariates--to account for the possibility that inclusion of these covariates in the model is overfitting:
lmFit(full.data[,112:119], model.matrix(~1+fake.meta1$SP+fake.meta1$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake1
lmFit(full.data[,112:119], model.matrix(~1+fake.meta2$SP+fake.meta2$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake2
lmFit(full.data[,112:119], model.matrix(~1+fake.meta3$SP+fake.meta3$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake3
lmFit(full.data[,112:119], model.matrix(~1+fake.meta4$SP+fake.meta4$Batch)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake4
newqqplot(-log10(fake1$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no SX, 1 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-6.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake2$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no SX, 2 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-7.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake3$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no SX, 3 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-8.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake4$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no SX, 4 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-9.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>lmFit(full.data[,112:119], model.matrix(~1+fake.meta1$SP+fake.meta1$SX)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake1
lmFit(full.data[,112:119], model.matrix(~1+fake.meta2$SP+fake.meta2$SX)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake2
lmFit(full.data[,112:119], model.matrix(~1+fake.meta3$SP+fake.meta3$SX)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake3</code></pre>
<pre><code>Coefficients not estimable: fake.meta3$SXM </code></pre>
<pre><code>Warning: Partial NA coefficients for 12876 probe(s)

Warning: Estimation of var.prior failed - set to default value</code></pre>
<pre class="r"><code>lmFit(full.data[,112:119], model.matrix(~1+fake.meta4$SP+fake.meta4$SX)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake4
newqqplot(-log10(fake1$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no BTC, 1 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-10.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake2$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no BTC, 2 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-11.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake3$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no BTC, 3 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-12.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake4$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design no BTC, 4 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-13.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>lmFit(full.data[,112:119], model.matrix(~1+fake.meta1$SP)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake1
lmFit(full.data[,112:119], model.matrix(~1+fake.meta2$SP)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake2
lmFit(full.data[,112:119], model.matrix(~1+fake.meta3$SP)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake3
lmFit(full.data[,112:119], model.matrix(~1+fake.meta4$SP)) %&gt;% eBayes(.) %&gt;% topTable(., coef=2, sort.by=&quot;none&quot;, number=Inf) -&gt; fake4
newqqplot(-log10(fake1$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design SP only, 1 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-14.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake2$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design SP only, 2 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-15.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake3$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design SP only, 3 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-16.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(fake4$P.Value), c(0.5, 0.75), &quot;QQ Plot, Shuffled Design SP only, 4 | 4&quot;)</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/QQ%20Plots-17.png" width="672" style="display: block; margin: auto;" /> These are slightly better, but many show some small degree of deflation. After looking at all these QQ plots concerns about p-value inflation are fairly assuaged, and itâ€™s again worth noting that there was no real cause for concern in the first place. Once again, I pulled out significant Hi-C hits from each species, so it makes sense that this set of hits might already be enriched for strong species differences. I conclude that the signal seen in the QQ plot is not an artifact of making incorrect assumptions in linear modeling.</p>
</div>
<div id="genomic-differences" class="section level3">
<h3>Genomic Differences</h3>
<p>However, we might still be concerned that some of the observed differences are not truly driven by biology, but due to differences in genome builds or other issues induced by liftOver. I now add several other metrics measuring differences in bin sizes and pair distances between humans and chimps, to help identify differences that may be primarily driven by mapping of orthology or different genome builds rather than true biology. I will then subset the QQ plots to particular classes of these hits and see if any pattern emerges. This utilizes the normal set of p-values from the original design conditioned upon discovery in 4 individuals. I also place hits into classes based on differences in bin size or distance between pair mates, and use a 3-dimensional plot to see if any class(es) of hits show strong inflation in their species p-values from linear modeling. This represents one of the final filtering steps.</p>
<pre class="r"><code>#To do this, I first have to pull out the mean start and end positions of bins for each of the species from the data:
H1startCmean &lt;- rowMeans(full.data[,c(&#39;hstart1-C&#39;, &#39;hstart1-D&#39;, &#39;hstart1-G&#39;, &#39;hstart1-H&#39;)], na.rm=TRUE)
H1endCmean &lt;- rowMeans(full.data[,c(&#39;hend1-C&#39;, &#39;hend1-D&#39;, &#39;hend1-G&#39;, &#39;hend1-H&#39;)], na.rm=TRUE)
H2startCmean &lt;- rowMeans(full.data[,c(&#39;hstart2-C&#39;, &#39;hstart2-D&#39;, &#39;hstart2-G&#39;, &#39;hstart2-H&#39;)], na.rm=TRUE)
H2endCmean &lt;- rowMeans(full.data[,c(&#39;hend2-C&#39;, &#39;hend2-D&#39;, &#39;hend2-G&#39;, &#39;hend2-H&#39;)], na.rm=TRUE)

C1startHmean &lt;- rowMeans(full.data[,c(&#39;cstart1-A&#39;, &#39;cstart1-B&#39;, &#39;cstart1-E&#39;, &#39;cstart1-F&#39;)], na.rm=TRUE) #this is identical and easier.
C1endHmean &lt;- rowMeans(full.data[,c(&#39;cend1-A&#39;, &#39;cend1-B&#39;, &#39;cend1-E&#39;, &#39;cend1-F&#39;)], na.rm=TRUE)
C2startHmean &lt;- rowMeans(full.data[,c(&#39;cstart2-A&#39;, &#39;cstart2-B&#39;, &#39;cstart2-E&#39;, &#39;cstart2-F&#39;)], na.rm=TRUE)
C2endHmean &lt;- rowMeans(full.data[,c(&#39;cend2-A&#39;, &#39;cend2-B&#39;, &#39;cend2-E&#39;, &#39;cend2-F&#39;)], na.rm=TRUE)
  
#Now, I use these data to add columns to the data frame for the sizes of bins and distance between bins. Note that I am only really looking at differences in the size of the &quot;orthologous&quot; bins called through liftover, as compared to their original size (10kb). Bin size differences in the values at the start of each individual&#39;s portion of the data frame for coordinates matching that species are merely due to size differences in reciprocal best hits liftover. The true size of bins within their own species is always 10kb. So here bin sizes being appended to the data frame are for lifted-over bins. I do the distance differences based on the HC-pair values (H1/H2 and C1/C2) that have been rounded to the nearest 10kb from the original values given by homer; since this should be balanced across species it shouldn&#39;t matter much. Worst case it would make the estimate off by 20kb, maximum.
H1sizeC &lt;- H1endCmean-H1startCmean
H2sizeC &lt;- H2endCmean-H2startCmean
full.data$H1diff &lt;- abs(10000-H1sizeC)
full.data$H2diff &lt;- abs(10000-H2sizeC)
C1sizeH &lt;- C1endHmean-C1startHmean
C2sizeH &lt;- C2endHmean-C2startHmean
full.data$C1diff &lt;- abs(10000-C1sizeH)
full.data$C2diff &lt;- abs(10000-C2sizeH)
full.data$Hdist &lt;- abs(as.numeric(sub(&quot;.*-&quot;, &quot;&quot;, full.data$H2))-as.numeric(sub(&quot;.*-&quot;, &quot;&quot;, full.data$H1)))
full.data$Cdist &lt;- abs(as.numeric(sub(&quot;.*-&quot;, &quot;&quot;, full.data$C2))-as.numeric(sub(&quot;.*-&quot;, &quot;&quot;, full.data$C1)))
full.data$dist_diff &lt;- abs(full.data$Hdist-full.data$Cdist)

#Now I look at the distributions of some of these metrics to inform me about how best to bin the data for filtering and further QC checking.
quantile(full.data$H1diff, na.rm=TRUE)</code></pre>
<pre><code>  0%  25%  50%  75% 100% 
   0    8   20   48 1097 </code></pre>
<pre class="r"><code>quantile(full.data$H2diff, na.rm=TRUE)</code></pre>
<pre><code>  0%  25%  50%  75% 100% 
   0    9   21   50  999 </code></pre>
<pre class="r"><code>quantile(full.data$C1diff, na.rm=TRUE)</code></pre>
<pre><code>  0%  25%  50%  75% 100% 
   0    8   21   49 1088 </code></pre>
<pre class="r"><code>quantile(full.data$C2diff, na.rm=TRUE)</code></pre>
<pre><code>  0%  25%  50%  75% 100% 
   0    9   21   50 1063 </code></pre>
<pre class="r"><code>quantile(full.data$dist_diff, na.rm=TRUE)</code></pre>
<pre><code>      0%      25%      50%      75%     100% 
       0        0        0    10000 17560000 </code></pre>
<pre class="r"><code>#From this I can see that the majority of bin size differences are relatively small (&lt;25 bp), and the majority of hits do not have a difference in distance between the mates in a pair across the species (all the way up to 50th percentile the distance difference is still 0). Now I&#39;ll take a look at some QQ plots filtering along these values to get an idea of if any of these technical orthology-calling artifacts are driving the inflation we see.
newqqplot(-log10(filter(full.data, H1diff&lt;21&amp;H2diff&lt;21&amp;C1diff&lt;21&amp;C2diff&lt;21)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Bin Size Changes &lt; 21 bp&quot;) #We can see that the QQplot looks a bit better if we only utilize hits where the bin size difference is less than the 50% percentile of their distribution.</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/Genomic%20Differences-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(full.data, H1diff&gt;=21&amp;H2diff&gt;=21&amp;C1diff&gt;=21&amp;C2diff&gt;=21)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Bin Size Changes &gt;= 21bp&quot;) #This doesn&#39;t look much different--what about the case where there are large differences in the size?</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/Genomic%20Differences-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(full.data, H1diff&gt;=100|H2diff&gt;=100|C1diff&gt;=100|C2diff&gt;=100)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Bin Size Changes &gt;= 100 bp&quot;) #It&#39;s hard to know what to make of this since here I am just allowing for any bin to have a size change greater than 100 bp. It looks fairly similar to the QQplot of the full data.</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/Genomic%20Differences-3.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(full.data, H1diff&gt;=500|H2diff&gt;=500|C1diff&gt;=500|C2diff&gt;=500)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Bin Size Changes &gt;= 500 bp&quot;) #It&#39;s hard to know what to make of this since here I am just allowing for any bin to have a size change greater than 500 bp.</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/Genomic%20Differences-4.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(full.data, H1diff&gt;=1000|H2diff&gt;=1000|C1diff&gt;=1000|C2diff&gt;=1000)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Bin Size Changes &gt;= 1000 bp&quot;) #It&#39;s hard to know what to make of this since here I am just allowing for any bin to have a size change greater than 1kb.</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/Genomic%20Differences-5.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#It may be hard to say anything super definitive about the bin size changes from these plots, but the fact that they all still show inflation, and I don&#39;t see any stark difference between bin size changes exceeding 100 bp, suggests to me that bin size is having a minimal effect here. Still, we will include it when looking at filtering criteria below for figuring out what hits might need to be removed still.

newqqplot(-log10(filter(full.data, dist_diff&gt;=100000)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Distance Diff &gt;= 100kb&quot;) #This is good to know--see EXTREMELY strong inflation amongst this class of p-values, perhaps giving another criteria for filtering</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/Genomic%20Differences-6.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(full.data, dist_diff&gt;=50000)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Distance Diff &gt;= 50kb&quot;) #This is good to know--see that the inflation is a little weaker if we move towards including more pairs that have smaller distance differences between the species. What about pairs where there is no difference?</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/Genomic%20Differences-7.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(full.data, dist_diff==0)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, NO Distance Diff&quot;) #Values are still inflated, but the first solid 50% of the distribution stays along the normal line--this is great!</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/Genomic%20Differences-8.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>newqqplot(-log10(filter(full.data, dist_diff&lt;=20000)$sp_pval), c(0.5, 0.75), &quot;QQ Plot, Distance Diff &lt;=20kb&quot;) #And now we can see the trend in the opposite direction--SLIGHT inflation of the p-values when including more hits that have a larger distance difference.</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/Genomic%20Differences-9.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#Based on the quantiles from before, the size differences have relatively little variation in their distribution. Hence I will take them and summarize them as a single value here:
sizediffs &lt;- rowMeans(select(full.data, H1diff, H2diff, C1diff, C2diff), na.rm=TRUE)
quantile(sizediffs, probs=seq(0, 1, 0.2))</code></pre>
<pre><code>    0%    20%    40%    60%    80%   100% 
  0.00  12.50  21.50  37.50 100.25 938.00 </code></pre>
<pre class="r"><code># #Now what I would like to do is find classes of hits--combinations between size and distance differences--that comprise roughly 10% of the data, or ~30k hits here. I will look at these classes in a 3-dimensional plot that includes size and distance differences as two of the axes, and the FDR from linear modeling on the 3rd. What I am in search of are classes of hits that show inflated FDR.
# plot3d &lt;- data.frame(bin_min=pmin(full.data$H1diff, full.data$H2diff, full.data$C1diff, full.data$C2diff, na.rm=TRUE), bin_max=pmax(full.data$H1diff, full.data$H2diff, full.data$C1diff, full.data$C2diff, na.rm=TRUE), sizediffs=sizediffs, dist_diff=full.data$dist_diff, FDR=full.data$sp_BH_pval)
# 
# #Of course, I already inherently know I will have a difficult time finding sets large enough with the bigger differences in distance, as only 10k or so of the hits even have a distance difference greater than 50kb. About half the hits have no distance difference, and of the remaining half, about half have size differences of 1-2 bins (10-20 kb), and half have greater size differences.
# 
# #First, I go in search of sets that will be large enough.
# nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&lt;10000)) #35k, a class of minimal changes--no distance difference, and minimal size difference.
# nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&lt;10000)) #35k, still minimal changes
# nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&lt;10000)) #35k, minimal changes still, bin size getting up there
# nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&lt;10000)) #35k, minimal changes still, bin size even higher though
# nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&lt;10000)) #And there&#39;s another 35k! With big bin size changes.
# 
# nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)) #23k, a class of minimal changes--no size difference, and minimal distance difference (1-2 bins off).
# nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)) #23k, small size difference, and minimal distance difference (1-2 bins off, 10-20 kb).
# nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)) #23k, minimal changes still, bin size getting up there, and minimal distance difference (1-2 bins off, 10-20 kb).
# nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)) #23k, minimal changes still, bin size even higher though, and minimal distance difference (1-2 bins off, 10-20 kb).
# nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)) #And there&#39;s another 23k! With big bin size changes, and minimal distance difference (1-2 bins off, 10-20 kb).
# 
# nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&gt;20000)) #11k, a class of large changes--big distance difference, and minimal size difference.
# nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&gt;20000)) #11k, a class of large changes--big distance difference, and relatively small size difference.
# nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&gt;20000)) #11k, a class of large changes--big distance difference, and median size difference.
# nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&gt;20000)) #11k, a class of large changes--big distance difference, and fairly large size difference.
# nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&gt;20000)) #11k, a class of the largest changes--big distance difference, and big size difference.
# 
# #Now, create a data frame with these classes, their sizes, and the number of hits in each of the classes that is at FDR &lt;= 0.05.
# true3d &lt;- data.frame(dist_class=c(rep(&quot;none&quot;, 5), rep(&quot;short&quot;, 5), rep(&quot;long&quot;, 5)), bin_quant=rep(1:5, 3), set_size=c(nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&lt;10000)), nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&lt;10000)), nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&lt;10000)), nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&lt;10000)), nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&lt;10000)), nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)), nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)), nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)), nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)), nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000)), nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&gt;20000)), nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&gt;20000)), nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&gt;20000)), nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&gt;20000)), nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&gt;20000))), num_sig=c(nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&lt;10000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&lt;10000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&lt;10000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&lt;10000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&lt;10000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&gt;=10000&amp;dist_diff&lt;=20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=13.5&amp;dist_diff&gt;20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=23.33&amp;sizediffs&gt;13.5&amp;dist_diff&gt;20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=42.18750&amp;sizediffs&gt;23.33&amp;dist_diff&gt;20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&lt;=109.5&amp;sizediffs&gt;42.18750&amp;dist_diff&gt;20000&amp;FDR&lt;=0.05)), nrow(filter(plot3d, sizediffs&gt;109.5&amp;dist_diff&gt;20000&amp;FDR&lt;=0.05))))
# true3d$prop &lt;- true3d$num_sig/true3d$set_size #Get the proportion of these different sets that are significant (at or below 5% FDR)
# 
# #I will then take this data frame and export it to plot.ly&#39;s online interface, in order to make a 3D plot that will allow me to visualize FDR significance inflation in any of these sets (and subsequently filter them out). The 3D plot looks like this:
# htmltools::includeHTML(&quot;/Users/ittaieres/Hi-C/analysis/QQQC.html&quot;)
# 
# #Based on the 3D QQ quality control plot, the hit classes with larger distance-between-mates differences should be filtered out due to inflation of # hits significant @ 5% FDR. This gets rid of ~55k hits, or about a seventh of them. Essentially I am removing any hits that showed a difference in distance of greater than 20kb when lifting Over acros the species, to eliminate technical genomic differences that may drive signal in the species term:
# highclass &lt;- which(plot3d$dist_diff&gt;20000)
# full.data &lt;- full.data[-highclass,] #Just removed high class since it has the starkest effect on proportion of hits significant @ 5% FDR</code></pre>
<p>Now I have obliterated any remaining concerns about the QQ plot inflation, and filtered out another class of Hi-C significant hits where species differences may have been driven by issues with liftOver between genomes.</p>
</div>
<div id="volcano-plot-asymmetry" class="section level3">
<h3>Volcano Plot Asymmetry</h3>
<p>Now, I go to the asymmetry issue seen in the volcano plot on the linear modeling outputs. I first utilize the set of data conditioned upon discovery in 4 individuals, and break this information down on a chromosome-by-chromosome basis to see if there are particular chromosomes driving the asymmetry. Upon observation of chromosome-specific effects I quantify the extent of asymmetry on individual chromosomes using a null expectation of a binomial distribution with 50/50 probability of betas being positive or negative. I then repeat these analyses and visualize them on the final set of filtered data from above.</p>
<pre class="r"><code>#Here I once again show the volcano plot for 4 individuals. Observe the stark asymmetry with a pile-up of hits on the left side as compared to the right.
volcplot &lt;- data.frame(pval=-log10(full.data$sp_pval), beta=full.data$sp_beta, species=full.data$disc_species, chr=full.data$Hchr)
ggplot(data=volcplot, aes(x=beta, y=pval)) + geom_point() + xlab(&quot;Log2 Fold Change in Contact Frequency&quot;) + ylab(&quot;-log10 BH-corrected p-values&quot;) + ggtitle(&quot;Contact Frequency Differences&quot;) + coord_cartesian(xlim=c(-6, 6))</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/Volcano%20Plot%20Asymmetry-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#As expected, we see that hits which produce a strong negative beta in the linear model (suggesting a marked decrease in contact frequency in humans as compared to chimps) are primarily discovered as significant by homer in chimpanzees. The inverse also holds true for human discoveries. This is reassuring, but still, why the asymmetry? Here I break this plot down on a chromosome-by-chromosome basis to see if this is being driven by individual chromosomes ore is an overall issue with the technique or its processing:
#First rearrange chrs to make a prettier plot that has chrs sequential:
levels(volcplot$chr)</code></pre>
<pre><code> [1] &quot;chr1&quot;  &quot;chr10&quot; &quot;chr11&quot; &quot;chr12&quot; &quot;chr13&quot; &quot;chr14&quot; &quot;chr15&quot; &quot;chr16&quot;
 [9] &quot;chr17&quot; &quot;chr18&quot; &quot;chr19&quot; &quot;chr2&quot;  &quot;chr20&quot; &quot;chr21&quot; &quot;chr22&quot; &quot;chr3&quot; 
[17] &quot;chr4&quot;  &quot;chr5&quot;  &quot;chr6&quot;  &quot;chr7&quot;  &quot;chr8&quot;  &quot;chr9&quot;  &quot;chrX&quot; </code></pre>
<pre class="r"><code>volcplot$chr &lt;- factor(volcplot$chr, levels(volcplot$chr)[c(1, 12, 16:22, 2:11, 13:15, 23:24)]) #Reorder factor levels!
levels(volcplot$chr)</code></pre>
<pre><code> [1] &quot;chr1&quot;  &quot;chr2&quot;  &quot;chr3&quot;  &quot;chr4&quot;  &quot;chr5&quot;  &quot;chr6&quot;  &quot;chr7&quot;  &quot;chr8&quot; 
 [9] &quot;chr9&quot;  &quot;chr10&quot; &quot;chr11&quot; &quot;chr12&quot; &quot;chr13&quot; &quot;chr14&quot; &quot;chr15&quot; &quot;chr16&quot;
[17] &quot;chr17&quot; &quot;chr18&quot; &quot;chr19&quot; &quot;chr20&quot; &quot;chr21&quot; &quot;chr22&quot; &quot;chrX&quot; </code></pre>
<pre class="r"><code>ggplot(volcplot, aes(x=beta, y=pval, color=species)) + geom_point(size=0.01) + ggtitle(&quot;Volcano Plots by Chr&quot;) + facet_wrap(~as.factor(chr), nrow=5, ncol=5) + guides(color=FALSE) + ylab(&quot;-log10 p-values&quot;) + xlab(&quot;Log2 Fold Change in Contact Frequency&quot;) + coord_cartesian(xlim=c(-6, 6))</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/Volcano%20Plot%20Asymmetry-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#This is extremely interesting. It appears that the asymmetry seen is being driven primarily by only some of the chromosomes, and particularly ones where large-scale rearrangements have transpired between humans and chimps (e.g. chrs 2, 16, 17). This will warrant further investigation in another element of the analysis; for now, I am satisfied that the asymmetry is not an issue with the entire dataset but is confined to individual chromosomes.

#Now try to quantify the extent of asymmetry in the chromosomes, with a particular focus on hits that are statistically significant.
asym.stats &lt;- data.frame(chr=unique(full.data$Hchr), binom.p=rep(NA, 23), prop.h=rep(NA, 23), prop.c=rep(NA, 23))
rownames(asym.stats) &lt;- asym.stats$chr
for(chromo in unique(full.data$Hchr)){
  mydat &lt;- filter(full.data, Hchr==chromo, sp_BH_pval&lt;=0.05) #Iterate through chromosomes
  side &lt;- ifelse(mydat$sp_beta&lt;0, 0, 1) #Assign sides of the beta dist&#39;n to the betas
  asym.obs &lt;- min(sum(side==1), sum(side==0)) #Find which side of the beta dist&#39;n has less points, so I can use pbinom on default w/ lower.tail to find probability of observing a result as or MORE asymmetric than this one.
  asym.stats[chromo, 2] &lt;- pbinom(asym.obs, length(side), 0.5) #Find that probability with the assumption of 50/50 chance of landing on either side.
  asym.stats[chromo, 3] &lt;- sum(side==1)/length(side) #Find the proportion of the hits that fall on the human side of the distribution (positive, indicating increased contact frequency here in humans as compared to chimps)
  asym.stats[chromo, 4] &lt;- sum(side==0)/length(side) #Same thing as above, but for chimps this time.
}
#Now we can look at the actual results to quantify how asymmetric the significant hits are from each chromosome:
asym.stats</code></pre>
<pre><code>        chr      binom.p     prop.h     prop.c
chr9   chr9 4.882812e-04 0.00000000 1.00000000
chr11 chr11 2.730563e-04 0.17241379 0.82758621
chr8   chr8 1.875000e-01 0.80000000 0.20000000
chr12 chr12 9.765625e-04 0.00000000 1.00000000
chr13 chr13 7.629395e-06 1.00000000 0.00000000
chr14 chr14 3.515625e-02 0.12500000 0.87500000
chr15 chr15 6.310887e-30 0.00000000 1.00000000
chr16 chr16 3.125000e-01 0.25000000 0.75000000
chr17 chr17 1.123047e-02 0.15384615 0.84615385
chr10 chr10 3.637979e-12 1.00000000 0.00000000
chr18 chr18 2.500000e-01 0.00000000 1.00000000
chr19 chr19 1.049042e-05 0.95238095 0.04761905
chr20 chr20 1.250000e-01 0.00000000 1.00000000
chr21 chr21 2.328306e-10 0.00000000 1.00000000
chr22 chr22 4.930381e-32 0.00000000 1.00000000
chrX   chrX 1.938477e-01 0.66666667 0.33333333
chr1   chr1 2.127981e-06 0.13157895 0.86842105
chr2   chr2 1.050198e-01 0.34782609 0.65217391
chr3   chr3 5.000000e-01 0.48571429 0.51428571
chr4   chr4 3.061995e-13 0.03846154 0.96153846
chr5   chr5 2.365648e-01 0.41935484 0.58064516
chr6   chr6 5.908966e-03 0.20000000 0.80000000
chr7   chr7 1.349401e-79 1.00000000 0.00000000</code></pre>
<pre class="r"><code>#Now, make volcano plots by chromosome again, this time labeling each chromosome with its binomial p-value and the percentage of significant hits showing stronger contact frequencies in each species on either side of the distribution.
ggplot(data=volcplot, aes(x=beta, y=pval, color=species)) + geom_point(size=0.001) + ggtitle(&quot;Volcano Plots by Chr&quot;) + facet_wrap(~chr, nrow=5, ncol=5) + guides(color=FALSE) + ylab(&quot;-log10 BH-adjusted p-values&quot;) + xlab(&quot;Log2 Fold Change in Contact Frequency&quot;) + geom_text(data=asym.stats, aes(x=-4.5, y=0.75, label=paste(round(prop.c*100, digits=1), &quot;%&quot;, sep=&quot;&quot;), color=NULL), show.legend=FALSE, size=2) + geom_text(data=asym.stats, aes(x=4, y=0.75, label=paste(round(prop.h*100, digits=1), &quot;%&quot;, sep=&quot;&quot;), color=NULL), show.legend=FALSE, size=2) + geom_text(data=asym.stats, aes(x=0, y=4.75, label=signif(binom.p, digits=3), color=NULL), show.legend=FALSE, size=2) + coord_cartesian(xlim=c(-6, 6))</code></pre>
<p><img src="figure/juicer_linear_modeling_QC.Rmd/Volcano%20Plot%20Asymmetry-3.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#ggsave(&#39;~/Desktop/volcchr.jpg&#39;, device=&quot;jpeg&quot;, antialias=&quot;none&quot;) This was an earlier attempt at clearing up some image resolution blurriness with the text.
ggsave(&#39;~/Desktop/volcchr2.jpg&#39;, device=&quot;jpeg&quot;, dpi=5000) #Works well!</code></pre>
<pre><code>Saving 7 x 5 in image</code></pre>
<pre class="r"><code>#Write out the data with the new columns added on!
fwrite(full.data, &quot;~/Desktop/Hi-C/juicer.full.data.10.2018&quot;, quote = TRUE, sep = &quot;\t&quot;, row.names = FALSE, col.names = TRUE, na=&quot;NA&quot;, showProgress = FALSE)</code></pre>
<p>From this analysis we have dealt with some quality control issues, and filtered down the data to a final set of biologically significant Hi-C interaction frequencies, many of which appear species-specific. There are clearly strong differences between the species that make their 3D regulatory landscapes divergent. Now, I move to orthogonal gene expression analyses.</p>
</div>
<div id="session-information" class="section level2">
<h2>Session information</h2>
<!-- Insert the session information into the document -->
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>R version 3.4.0 (2017-04-21)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: OS X El Capitan 10.11.6

Matrix products: default
BLAS: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRblas.0.dylib
LAPACK: /Library/Frameworks/R.framework/Versions/3.4/Resources/lib/libRlapack.dylib

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] compiler  stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
 [1] bindrcpp_0.2        bedr_1.0.4          forcats_0.2.0      
 [4] purrr_0.2.4         readr_1.1.1         tibble_1.3.4       
 [7] tidyverse_1.2.1     edgeR_3.20.1        RColorBrewer_1.1-2 
[10] heatmaply_0.13.0    viridis_0.4.0       viridisLite_0.2.0  
[13] stringr_1.2.0       gplots_3.0.1        Hmisc_4.0-3        
[16] Formula_1.2-2       survival_2.41-3     lattice_0.20-35    
[19] dplyr_0.7.4         plotly_4.7.1        ggplot2_2.2.1      
[22] reshape2_1.4.2      data.table_1.10.4-3 tidyr_0.7.2        
[25] plyr_1.8.4          limma_3.34.3       

loaded via a namespace (and not attached):
 [1] colorspace_1.3-2     class_7.3-14         modeltools_0.2-21   
 [4] mclust_5.4           rprojroot_1.2        htmlTable_1.11.0    
 [7] futile.logger_1.4.3  base64enc_0.1-3      rstudioapi_0.7      
[10] flexmix_2.3-14       mvtnorm_1.0-6        lubridate_1.7.1     
[13] xml2_1.1.1           codetools_0.2-15     splines_3.4.0       
[16] R.methodsS3_1.7.1    mnormt_1.5-5         robustbase_0.92-8   
[19] knitr_1.17           jsonlite_1.5         broom_0.4.3         
[22] cluster_2.0.6        kernlab_0.9-25       R.oo_1.21.0         
[25] httr_1.3.1           backports_1.1.1      assertthat_0.2.0    
[28] Matrix_1.2-12        lazyeval_0.2.1       cli_1.0.0           
[31] acepack_1.4.1        htmltools_0.3.6      tools_3.4.0         
[34] gtable_0.2.0         glue_1.2.0           Rcpp_0.12.14        
[37] cellranger_1.1.0     trimcluster_0.1-2    gdata_2.18.0        
[40] nlme_3.1-131         iterators_1.0.8      fpc_2.1-10          
[43] psych_1.7.8          testthat_1.0.2       rvest_0.3.2         
[46] gtools_3.5.0         dendextend_1.6.0     DEoptimR_1.0-8      
[49] MASS_7.3-47          scales_0.5.0         TSP_1.1-5           
[52] hms_0.4.0            parallel_3.4.0       lambda.r_1.2        
[55] yaml_2.1.15          gridExtra_2.3        rpart_4.1-11        
[58] latticeExtra_0.6-28  stringi_1.1.6        gclus_1.3.1         
[61] foreach_1.4.3        checkmate_1.8.5      seriation_1.2-2     
[64] caTools_1.17.1       rlang_0.1.4          pkgconfig_2.0.1     
[67] prabclus_2.2-6       bitops_1.0-6         evaluate_0.10.1     
[70] bindr_0.1            labeling_0.3         htmlwidgets_0.9     
[73] magrittr_1.5         R6_2.2.2             haven_1.1.0         
[76] whisker_0.3-2        foreign_0.8-69       nnet_7.3-12         
[79] modelr_0.1.1         crayon_1.3.4         futile.options_1.0.0
[82] KernSmooth_2.23-15   rmarkdown_1.8        locfit_1.5-9.1      
[85] grid_3.4.0           readxl_1.0.0         git2r_0.19.0        
[88] digest_0.6.12        diptest_0.75-7       webshot_0.5.0       
[91] VennDiagram_1.6.18   R.utils_2.6.0        stats4_3.4.0        
[94] munsell_0.4.3        registry_0.5        </code></pre>
</div>

<hr>
<p>
    This <a href="http://rmarkdown.rstudio.com">R Markdown</a> site was created with <a href="https://github.com/jdblischak/workflowr">workflowr</a>
</p>
<hr>

<!-- To enable disqus, uncomment the section below and provide your disqus_shortname -->

<!-- disqus
  <div id="disqus_thread"></div>
    <script type="text/javascript">
        /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
        var disqus_shortname = 'rmarkdown'; // required: replace example with your forum shortname

        /* * * DON'T EDIT BELOW THIS LINE * * */
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
-->


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
